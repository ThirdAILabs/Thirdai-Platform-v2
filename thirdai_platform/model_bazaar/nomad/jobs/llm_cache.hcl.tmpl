job "llm-cache" {
  datacenters = ["dc1"]

  type = "service"

  group "llm-cache" {
    count = 1

    network {
      port "llm-cache-http" {
        {{ if isDocker .Driver }}
          to = 80
        {{ end }}
      }
    }

    service {
      name = "llm-cache"
      port = "llm-cache-http"
      provider = "nomad"

      tags = [
        "traefik.enable=true",
        "traefik.http.routers.llm-cache-http.rule=PathPrefix(`/cache/`)",
        "traefik.http.routers.llm-cache-http.priority=10"
      ]
    }

    task "backend" {
      {{ if isLocal .Driver }}
        driver = "raw_exec"
      {{ else if isDocker .Driver }}  
        driver = "docker"
      {{ end }}

      env {
        MODEL_BAZAAR_ENDPOINT = "{{ .ModelBazaarEndpoint }}"
        LICENSE_KEY = "{{ .LicenseKey }}"
        {{ if isDocker .Driver }}
        MODEL_BAZAAR_DIR = "/model_bazaar"
        {{ else if isLocal .Driver }}
        MODEL_BAZAAR_DIR = "{{ .ShareDir }}"
        {{ end }}
      }

      config {
        {{ if isDocker .Driver }}  
          {{ with .Driver }}
          image = "{{ .Registry }}/{{ .ImageName }}:{{ .Tag }}"
          image_pull_timeout = "15m"
          ports = ["llm-cache-http"]
          auth {
            username = "{{ .DockerUsername }}"
            password = "{{ .DockerPassword }}"
            server_address = "{{ .Registry }}"
          }
          {{ end }}
          volumes = [
            "{{ .ShareDir }}:/model_bazaar"
          ]
          command = "python3"
          args    = ["-m", "uvicorn", "main:app", "--app-dir", "llm_cache_job", "--host", "0.0.0.0", "--port", "80"]
        {{ else if isLocal .Driver }}
          command = "/bin/sh"
          {{ with .Driver }}
          args    = ["-c", "cd {{ .PlatformDir }} && {{ .PythonPath }} -m uvicorn main:app --app-dir llm_cache_job --host 0.0.0.0 --port ${NOMAD_PORT_llm_cache_http}"]
          {{ end }}
        {{ end }}
      }

      resources {
        cpu = 2400
        memory = 5000
      }
    }
  }
}